{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from IPython.display import JSON\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foursquare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send a request to Foursquare with a small radius (1000m) for all the bike stations in your city of choice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Foursquare V3 endpoint\n",
    "ENDPOINTfs = 'https://api.foursquare.com/v3/places/search'\n",
    "HEADERSfs = {'Authorization': os.environ['Foursquare_API'], 'Accept':'application/json'}\n",
    "PARAMSfs={'ll':'49.262487,-123.114397', 'radius':1000, 'limit':50, 'categories':'13000'}\n",
    "#response = requests.get(url = ENDPOINTfs, params = PARAMSfs,headers=HEADERSfs)\n",
    "\n",
    "df = pd.read_csv('../data/city_bikes.csv', index_col='id')\n",
    "\n",
    "rawResultsFS = []\n",
    "for lat, long in zip(df['latitude'], df['longitude']):\n",
    "    PARAMSfs['ll'] = f'{lat},{long}'\n",
    "    response = requests.get(url = ENDPOINTfs, params = PARAMSfs,headers=HEADERSfs)\n",
    "    rawResultsFS.append(response.json())\n",
    "\n",
    "#save raw results\n",
    "with open(\"../data/rawFSdataDineDrink.json\", \"w\") as outfile:\n",
    "    json.dump(rawResultsFS, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Foursquare V2 endpoint\n",
    "ENDPOINTfs = 'https://api.foursquare.com/v2/venues/explore'\n",
    "HEADERSfs = {'Accept':'application/json'}\n",
    "PARAMSfs={'ll':'49.270721,-123.146175', 'radius':1000, 'limit':100, 'v':20230730, 'offset':100,\n",
    "         'client_id':os.environ['Foursquare_IDv2'], 'client_secret':os.environ['Foursquare_SECRETv2']}\n",
    "#response = requests.get(url = ENDPOINTfs, params = PARAMSfs,headers=HEADERSfs)\n",
    "\n",
    "\n",
    "#do some random point checks on the resultant data frames\n",
    "# obj = response.json()\n",
    "# testRes = [x['venue']['categories'][0]['name'] for x in obj['response']['groups'][0]['items'] if 'Japanese Restaurant' in x['venue']['categories'][0]['name']]\n",
    "\n",
    "df = pd.read_csv('../data/city_bikes.csv')\n",
    "\n",
    "rawResultsFS = []\n",
    "for lat, long in zip(df['latitude'], df['longitude']):\n",
    "    PARAMSfs['ll'] = f'{lat},{long}'\n",
    "    response = requests.get(url = ENDPOINTfs, params = PARAMSfs,headers=HEADERSfs)\n",
    "    rawResultsFS.append(response.json())\n",
    "\n",
    "#save raw results\n",
    "with open(\"../data/rawFSdataV2All-100-200.json\", \"w\") as outfile:\n",
    "    json.dump(rawResultsFS, outfile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse through the response to get the POI (such as restaurants, bars, etc) details you want (ratings, name, location, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Foursquare V3 endpoint search\n",
    "with open('../data/rawFSdataDineDrink.json', 'r') as openfile:\n",
    "    rawResults = json.load(openfile)\n",
    "\n",
    "df_cb = pd.read_csv('../data/city_bikes.csv')\n",
    "\n",
    "fsPOI = {'bikeStationID' : [], 'name' : [], 'latitude' : [], 'longitude' : [], 'category' : []}\n",
    "idIdx = 0 #index to traverse through city bikes data frame\n",
    "\n",
    "for rawPOI in rawResults:\n",
    "    for poi in rawPOI['results']: #data in inner loop was generated with coordinates in each row of city bikes data frame\n",
    "        try:\n",
    "            fsPOI['bikeStationID'].append(df_cb.loc[idIdx, 'id'])\n",
    "            fsPOI['name'].append(poi['name'])\n",
    "            fsPOI['latitude'].append(poi['geocodes']['main']['latitude'])\n",
    "            fsPOI['longitude'].append(poi['geocodes']['main']['longitude'])\n",
    "            cats = [cat['name'] for cat in poi['categories']]\n",
    "            fsPOI['category'].append(','.join(cats)) #get all the categories\n",
    "        except Exception as e:\n",
    "            print(f\"error occurred on index {idIdx}. Info: {type(e).__name__}\")\n",
    "    idIdx += 1 #increment index in outer loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error occurred on index 244. Info: KeyError\n",
      "error occurred on index 244. Info: KeyError\n"
     ]
    }
   ],
   "source": [
    "#Foursquare V2 endpoint broad search. API decides which are the most common/popular POIs\n",
    "with open('../data/rawFSdataV2All-1-00.json', 'r') as openfile:\n",
    "    rawResults = json.load(openfile)\n",
    "\n",
    "with open('../data/rawFSdataV2All-100-200.json', 'r') as openfile:\n",
    "    rawResults.extend(json.load(openfile))\n",
    "    \n",
    "#to get the city bike station ids\n",
    "df_cb = pd.read_csv('../data/city_bikes.csv')\n",
    "cb_totRows = df_cb['id'].count()\n",
    "\n",
    "#columns for the data frame\n",
    "fsPOI = {'bikeStationID' : [], 'name' : [], 'latitude' : [], 'longitude' : [], 'category' : []}\n",
    "idIdx = 0 #index to traverse through city bikes data frame\n",
    "for rawPOI in rawResults:\n",
    "    try: #groups key sometimes does not exist  \n",
    "        for poi in rawPOI['response']['groups'][0]['items']: #data in inner loop was generated with coordinates in each row of city bikes data frame\n",
    "            fsPOI['bikeStationID'].append(df_cb.loc[idIdx, 'id'])\n",
    "            fsPOI['name'].append(poi['venue']['name'])\n",
    "            fsPOI['latitude'].append(poi['venue']['location']['lat'])\n",
    "            fsPOI['longitude'].append(poi['venue']['location']['lng'])\n",
    "            cats = [cat['name'] for cat in poi['venue']['categories']]\n",
    "            fsPOI['category'].append(','.join(cats)) #get all the categories  \n",
    "    except Exception as e:\n",
    "        print(f\"error occurred on index {idIdx}. Info: {type(e).__name__}\")\n",
    "    if idIdx == cb_totRows - 1: #reset counter if there are more than one datasets combined\n",
    "        idIdx = 0\n",
    "    else:\n",
    "        idIdx += 1 #increment index in outer loop\n",
    "#Note: error will occur on the last coordinates of city bikes because it has (0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put your parsed results into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fs = pd.DataFrame(fsPOI)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send a request to Yelp with a small radius (1000m) for all the bike stations in your city of choice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENDPOINTyelp = 'https://api.yelp.com/v3/businesses/search'\n",
    "HEADERSyelp = {\n",
    "    'Accept': 'application/json',\n",
    "    'Authorization': 'Bearer %s' % os.environ['Yelp_API']}\n",
    "PARAMSyelp = {'latitude':49.262487, 'longitude':-123.114397, 'radius': 1000, 'limit':50, 'categories':'coffee, All' }\n",
    "#response = requests.get(url = ENDPOINTyelp, params = PARAMSyelp, headers = HEADERSyelp)\n",
    "\n",
    "df = pd.read_csv('../data/city_bikes.csv')\n",
    "#note that we do this in two batches. First with offset 0, then with offset 50\n",
    "rawResultsYelp = []\n",
    "for lat, long in zip(df['latitude'], df['longitude']):\n",
    "    PARAMSyelp['latitude'] = lat\n",
    "    PARAMSyelp['longitude'] = long\n",
    "    response = requests.get(url = ENDPOINTyelp, params = PARAMSyelp, headers = HEADERSyelp)\n",
    "    rawResultsYelp.append(response.json())\n",
    "\n",
    "#save raw results (commented out to avoid accidentally over-writing file)\n",
    "# with open(\"../data/rawYelpDataCoffee.json\", \"w\") as outfile:\n",
    "#     json.dump(rawResultsYelp, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse through the response to get the POI (such as restaurants, bars, etc) details you want (ratings, name, location, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Broad search. API decides which are the most common/popular POIs\n",
    "with open('../data/rawYelpData1-50.json', 'r') as openfile:\n",
    "    rawYelpData = json.load(openfile)\n",
    "\n",
    "with open('../data/rawYelpData50-100.json', 'r') as openfile:\n",
    "    rawYelpData.extend(json.load(openfile))\n",
    "\n",
    "#to get the city bike station ids\n",
    "df_cb = pd.read_csv('../data/city_bikes.csv')\n",
    "cb_totRows = df_cb['id'].count()\n",
    "\n",
    "\n",
    "idIdx = 0 #index to traverse through city bikes data frame\n",
    "#columns for the data frame\n",
    "yelpPOI = {'bikeStationID' : [], 'name' : [], 'latitude' : [], 'longitude' : [], 'category' : [], 'rating' : [], 'numReviews' : []}\n",
    "for rawPOI in rawYelpData:\n",
    "    for poi in rawPOI['businesses']: #data in inner loop was generated with coordinates in each row of city bikes data frame\n",
    "        try:\n",
    "            yelpPOI['bikeStationID'].append(df_cb.loc[idIdx, 'id'])\n",
    "            yelpPOI['name'].append(poi['name'])\n",
    "            yelpPOI['latitude'].append(poi['coordinates']['latitude'])\n",
    "            yelpPOI['longitude'].append(poi['coordinates']['longitude'])\n",
    "            cats = [cat['title'] for cat in poi['categories']]\n",
    "            yelpPOI['category'].append(','.join(cats)) #get all the categories  \n",
    "            #yelpPOI['category'].append(poi['categories'][0]['title'])  \n",
    "            yelpPOI['rating'].append(poi['rating'])  \n",
    "            yelpPOI['numReviews'].append(poi['review_count'])\n",
    "        except Exception as e:\n",
    "            print(f\"error occurred on index {idIdx}. Info: {type(e).__name__}\")\n",
    "\n",
    "    if idIdx == cb_totRows - 1: #reset counter if there are more than one datasets combined\n",
    "        idIdx = 0\n",
    "    else:\n",
    "        idIdx += 1 #increment index in outer loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'Restaurants' specifically only\n",
    "with open('../data/rawYelpDataRestaurants.json', 'r') as openfile:\n",
    "    rawYelpData = json.load(openfile)\n",
    "#to get the city bike station ids\n",
    "df_cb = pd.read_csv('../data/city_bikes.csv')\n",
    "cb_totRows = df_cb['id'].count()\n",
    "\n",
    "idIdx = 0 #index to traverse through city bikes data frame\n",
    "#columns for the data frame\n",
    "yelp_restaurants = {'bikeStationID' : [], 'name' : [], 'latitude' : [], 'longitude' : [], 'category' : [], 'rating' : [], 'numReviews' : []}\n",
    "for rawPOI in rawYelpData:\n",
    "    for poi in rawPOI['businesses']: #data in inner loop was generated with coordinates in each row of city bikes data frame\n",
    "        try:\n",
    "            yelp_restaurants['bikeStationID'].append(df_cb.loc[idIdx, 'id'])\n",
    "            yelp_restaurants['name'].append(poi['name'])\n",
    "            yelp_restaurants['latitude'].append(poi['coordinates']['latitude'])\n",
    "            yelp_restaurants['longitude'].append(poi['coordinates']['longitude'])\n",
    "            cats = [cat['title'] for cat in poi['categories']]\n",
    "            yelp_restaurants['category'].append(','.join(cats)) #get all the categories  \n",
    "            #yelp_restaurants['category'].append(poi['categories'][0]['title'])  \n",
    "            yelp_restaurants['rating'].append(poi['rating'])  \n",
    "            yelp_restaurants['numReviews'].append(poi['review_count'])\n",
    "        except Exception as e:\n",
    "            print(f\"error occurred on index {idIdx}. Info: {type(e).__name__}\")\n",
    "\n",
    "    if idIdx == cb_totRows - 1: #reset counter if there are more than one datasets combined\n",
    "        idIdx = 0\n",
    "    else:\n",
    "        idIdx += 1 #increment index in outer loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'Coffee' specifically only\n",
    "with open('../data/rawYelpDataCoffee.json', 'r') as openfile:\n",
    "    rawYelpData = json.load(openfile)\n",
    "#to get the city bike station ids\n",
    "df_cb = pd.read_csv('../data/city_bikes.csv')\n",
    "cb_totRows = df_cb['id'].count()\n",
    "\n",
    "idIdx = 0 #index to traverse through city bikes data frame\n",
    "#columns for the data frame\n",
    "yelp_coffee = {'bikeStationID' : [], 'name' : [], 'latitude' : [], 'longitude' : [], 'category' : [], 'rating' : [], 'numReviews' : []}\n",
    "for rawPOI in rawYelpData:\n",
    "    for poi in rawPOI['businesses']: #data in inner loop was generated with coordinates in each row of city bikes data frame\n",
    "        try:\n",
    "            yelp_coffee['bikeStationID'].append(df_cb.loc[idIdx, 'id'])\n",
    "            yelp_coffee['name'].append(poi['name'])\n",
    "            yelp_coffee['latitude'].append(poi['coordinates']['latitude'])\n",
    "            yelp_coffee['longitude'].append(poi['coordinates']['longitude'])\n",
    "            cats = [cat['title'] for cat in poi['categories']]\n",
    "            yelp_coffee['category'].append(','.join(cats)) #get all the categories  \n",
    "            #yelp_coffee['category'].append(poi['categories'][0]['title'])  \n",
    "            yelp_coffee['rating'].append(poi['rating'])  \n",
    "            yelp_coffee['numReviews'].append(poi['review_count'])\n",
    "        except Exception as e:\n",
    "            print(f\"error occurred on index {idIdx}. Info: {type(e).__name__}\")\n",
    "\n",
    "    if idIdx == cb_totRows - 1: #reset counter if there are more than one datasets combined\n",
    "        idIdx = 0\n",
    "    else:\n",
    "        idIdx += 1 #increment index in outer loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put your parsed results into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yelp_restaurants = pd.DataFrame(yelpPOI)\n",
    "df_yelp_restaurants.to_csv('../data/yelp_POIall.csv', index=False)\n",
    "df_yelp_restaurants = pd.DataFrame(yelp_restaurants)\n",
    "df_yelp_restaurants.to_csv('../data/yelp_restaurants.csv', index=False)\n",
    "df_yelp_coffee = pd.DataFrame(yelp_coffee)\n",
    "df_yelp_coffee.to_csv('../data/yelp_coffee.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which API provided you with more complete data? Provide an explanation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The Yelp API provided more complete data. It gives ratings and the number of ratings of points of interest (POI) which were not available in the Foursquare API. The Foursquare V3 API also has a limitation of 50 POIs per API call so the amountof data is limited. The Yelp API is also limited by 50 POI per API call but it also offers an offset parameter that allows retrieval of more results. However, the Foursquare V2 API allows for retrieval of up to 100 POIs per API call along with the offset parameter to retrieve more results. I noticed sometimes there are multiple descriptions of categories returned by the APIs so I concatenated all of them to increase the probability of matches when the data is exported to a data frame. \n",
    "\n",
    "##### Since the Foursquare V2 and Yelp APIs can provide more data, I also made API calls to them without any filter for the returned data and let the API decide on the matches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the top 10 restaurants according to their rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bikeStationID</th>\n",
       "      <th>name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>numReviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>4</td>\n",
       "      <td>Manoush'eh</td>\n",
       "      <td>49.276671</td>\n",
       "      <td>-123.125701</td>\n",
       "      <td>Mediterranean</td>\n",
       "      <td>5.0</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>15</td>\n",
       "      <td>Incognito Coffee</td>\n",
       "      <td>49.280370</td>\n",
       "      <td>-123.119690</td>\n",
       "      <td>Coffee &amp; Tea,Sandwiches,Breakfast &amp; Brunch</td>\n",
       "      <td>5.0</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>4</td>\n",
       "      <td>Number E Food</td>\n",
       "      <td>49.277569</td>\n",
       "      <td>-123.131018</td>\n",
       "      <td>Sandwiches,Coffee &amp; Tea</td>\n",
       "      <td>5.0</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>69</td>\n",
       "      <td>Mazahr Lebanese Kitchen</td>\n",
       "      <td>49.261551</td>\n",
       "      <td>-123.138305</td>\n",
       "      <td>Lebanese</td>\n",
       "      <td>5.0</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5359</th>\n",
       "      <td>221</td>\n",
       "      <td>The Garden Strathcona</td>\n",
       "      <td>49.280760</td>\n",
       "      <td>-123.085630</td>\n",
       "      <td>Cafes,Bakeries,Accessories</td>\n",
       "      <td>5.0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>32</td>\n",
       "      <td>Arike Restaurant</td>\n",
       "      <td>49.286805</td>\n",
       "      <td>-123.140856</td>\n",
       "      <td>African,Cocktail Bars,Canadian (New)</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>27</td>\n",
       "      <td>Ignite Pizzeria</td>\n",
       "      <td>49.277240</td>\n",
       "      <td>-123.118580</td>\n",
       "      <td>Pizza</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>66</td>\n",
       "      <td>True Nosh</td>\n",
       "      <td>49.265195</td>\n",
       "      <td>-123.137091</td>\n",
       "      <td>Health Markets,Cafes,Gluten-Free</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12011</th>\n",
       "      <td>3000</td>\n",
       "      <td>Pasta Panino</td>\n",
       "      <td>37.761014</td>\n",
       "      <td>-122.435911</td>\n",
       "      <td>Italian,Pasta Shops</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>5</td>\n",
       "      <td>The Magnet</td>\n",
       "      <td>49.282402</td>\n",
       "      <td>-123.111079</td>\n",
       "      <td>Beer Bar,Tapas/Small Plates,Cocktail Bars</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bikeStationID                     name   latitude   longitude  \\\n",
       "74                 4               Manoush'eh  49.276671 -123.125701   \n",
       "467               15         Incognito Coffee  49.280370 -123.119690   \n",
       "96                 4            Number E Food  49.277569 -123.131018   \n",
       "1825              69  Mazahr Lebanese Kitchen  49.261551 -123.138305   \n",
       "5359             221    The Garden Strathcona  49.280760 -123.085630   \n",
       "911               32         Arike Restaurant  49.286805 -123.140856   \n",
       "835               27          Ignite Pizzeria  49.277240 -123.118580   \n",
       "1799              66                True Nosh  49.265195 -123.137091   \n",
       "12011           3000             Pasta Panino  37.761014 -122.435911   \n",
       "135                5               The Magnet  49.282402 -123.111079   \n",
       "\n",
       "                                         category  rating  numReviews  \n",
       "74                                  Mediterranean     5.0         230  \n",
       "467    Coffee & Tea,Sandwiches,Breakfast & Brunch     5.0         173  \n",
       "96                        Sandwiches,Coffee & Tea     5.0         138  \n",
       "1825                                     Lebanese     5.0          46  \n",
       "5359                   Cafes,Bakeries,Accessories     5.0          36  \n",
       "911          African,Cocktail Bars,Canadian (New)     5.0          25  \n",
       "835                                         Pizza     5.0          20  \n",
       "1799             Health Markets,Cafes,Gluten-Free     5.0          19  \n",
       "12011                         Italian,Pasta Shops     5.0          18  \n",
       "135     Beer Bar,Tapas/Small Plates,Cocktail Bars     5.0          17  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yelp_restaurants.groupby(['name', 'rating', 'numReviews']).head(1).sort_values(['rating', 'numReviews'], ascending=[False,False]).nlargest(10,['rating'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
